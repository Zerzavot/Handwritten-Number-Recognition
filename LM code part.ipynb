{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' using MNIST dataset.\n",
    "\n",
    " 99.25% test accuracy\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Save the model\n",
    "model.save('mnistCNN.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0912 10:37:06.965173  2440 deprecation_wrapper.py:119] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0912 10:37:06.988058  2440 deprecation_wrapper.py:119] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0912 10:37:07.024074  2440 deprecation_wrapper.py:119] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0912 10:37:07.024074  2440 deprecation_wrapper.py:119] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0912 10:37:07.028051  2440 deprecation_wrapper.py:119] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0912 10:37:07.036052  2440 deprecation.py:506] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0912 10:37:07.174663  2440 deprecation_wrapper.py:119] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0912 10:37:07.410581  2440 deprecation_wrapper.py:119] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0912 10:37:07.686514  2440 deprecation.py:323] From C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value is 5 3 5 4 3 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FOR IMAGE SAMPLES\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('mnistCNN.h5')\n",
    "#model = load_model('digit_classifier2.h5')\n",
    "\n",
    "\n",
    "def get_numbers(y_pred):\n",
    "    for number, per in enumerate(y_pred[0]):\n",
    "        if per != 0:\n",
    "            final_number = str(int(number))\n",
    "            per = round((per * 100), 2)\n",
    "            return final_number, per\n",
    "\n",
    "        \n",
    "#img=cv2.imread(\"MNISTsamples.png\")\n",
    "img=cv2.imread(\"indir14.png\")\n",
    "\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "img_gau = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "ret, thresh = cv2.threshold(img_gau, 80, 255, cv2.THRESH_BINARY_INV)\n",
    "#cv2.imshow(\"Frame thersh\",thresh)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "#cv2.imshow(\"Frame dilation\", thresh)\n",
    "\n",
    "edged = cv2.Canny(dilation, 50, 250)\n",
    "#cv2.imshow(\"Frame edged\", thresh)\n",
    "\n",
    "#key = cv2.waitKey(0)\n",
    "'''if key == 27:\n",
    "    break\n",
    "elif key & 0xFF == ord('c'):'''\n",
    "\n",
    "cv2.imwrite('capture.jpg',img)\n",
    "capture_img = cv2.imread('capture.jpg')\n",
    "\n",
    "img2 = capture_img.copy()\n",
    "img_gray = cv2.cvtColor(capture_img, cv2.COLOR_RGB2GRAY)\n",
    "img_gau = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "ret, thresh = cv2.threshold(img_gau, 80, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "edged = cv2.Canny(dilation, 50, 250)\n",
    "\n",
    "contours, hierachy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "num_str = ''\n",
    "per = ''\n",
    "\n",
    "num_list = []\n",
    "\n",
    "if len(contours) > 0:\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 2500:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img2, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
    "\n",
    "            new_img = thresh[y:y + h, x:x + w]\n",
    "            new_img2 = cv2.resize(new_img, (28, 28))\n",
    "            im2arr = np.array(new_img2)\n",
    "            im2arr = im2arr.reshape(1, 28, 28, 1)\n",
    "            y_pred = model.predict(im2arr)\n",
    "\n",
    "            num, per = get_numbers(y_pred)\n",
    "            num_list.append(str(int(num)))\n",
    "            num_str = '[' + str(str(int(num))) + ']'\n",
    "            cv2.putText(img2, num_str, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "str1 = ' '.join(num_list)\n",
    "if (str1 != ''):\n",
    "    y_p = str('Predicted Value is ' + str(str1))\n",
    "    print(y_p)\n",
    "    cv2.putText(img2, y_p, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.imshow(\"Capture Frame\", img2)\n",
    "#cv2.imshow(\"Contours Frame\", thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR VIDEO SAMPLES\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('mnistCNN.h5')\n",
    "\n",
    "def get_numbers(y_pred):\n",
    "    for number, per in enumerate(y_pred[0]):\n",
    "        if per != 0:\n",
    "            final_number = str(int(number))\n",
    "            per = round((per * 100), 2)\n",
    "            return final_number, per\n",
    "\n",
    "#cameradan girdi için \"project.mp4\" yazan kısma 0 yazın\n",
    "video = cv2.VideoCapture(\"project.mp4\")\n",
    "if(video.isOpened()):\n",
    "    while True:\n",
    "        check, img = video.read()\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "\n",
    "        #Display purpose\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img_gau = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "        ret, thresh = cv2.threshold(img_gau, 80, 255, cv2.THRESH_BINARY_INV)\n",
    "        cv2.imshow(\"Frame thersh\",thresh)\n",
    "\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "        cv2.imshow(\"Frame dilation\", thresh)\n",
    "\n",
    "        edged = cv2.Canny(dilation, 50, 250)\n",
    "        cv2.imshow(\"Frame edged\", thresh)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == 27:\n",
    "            break\n",
    "        elif key & 0xFF == ord('c'):\n",
    "            cv2.imwrite('capture.jpg',img)\n",
    "            capture_img = cv2.imread('capture.jpg')\n",
    "\n",
    "            img2 = capture_img.copy()\n",
    "            img_gray = cv2.cvtColor(capture_img, cv2.COLOR_RGB2GRAY)\n",
    "            img_gau = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "            ret, thresh = cv2.threshold(img_gau, 80, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "            edged = cv2.Canny(dilation, 50, 250)\n",
    "\n",
    "            contours, hierachy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            num_str = ''\n",
    "            per = ''\n",
    "\n",
    "            num_list = []\n",
    "            if len(contours) > 0:\n",
    "                for c in contours:\n",
    "                    if cv2.contourArea(c) > 2500:\n",
    "                        x, y, w, h = cv2.boundingRect(c)\n",
    "                        cv2.rectangle(img2, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
    "\n",
    "                        new_img = thresh[y:y + h, x:x + w]\n",
    "                        new_img2 = cv2.resize(new_img, (28, 28))\n",
    "                        im2arr = np.array(new_img2)\n",
    "                        im2arr = im2arr.reshape(1, 28, 28, 1)\n",
    "                        y_pred = model.predict(im2arr)\n",
    "\n",
    "                        num, per = get_numbers(y_pred)\n",
    "                        num_list.append(str(int(num)))\n",
    "                        num_str = '[' + str(str(int(num))) + ']'\n",
    "                        cv2.putText(img2, num_str, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            str1 = ' '.join(num_list)\n",
    "            if (str1 != ''):\n",
    "                y_p = str('Predicted Value is ' + str(str1))\n",
    "                print(y_p)\n",
    "                cv2.putText(img2, y_p, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            cv2.imshow(\"Capture Frame\", img2)\n",
    "            cv2.imshow(\"Contours Frame\", thresh)\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
