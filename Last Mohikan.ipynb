{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL EĞİTİMİ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BATCH_SIZE**: Her 128 örnekte bir adım atmak demektir.Yani ilk 128 sample alınacak traininge sokulacak ardından 129-256 arası alınacak. Burada karşılaşılan en önemli sorun son sette belirtilen kadar sample kalamaması.Bu problem şu şekilde çözülür;son set kaç tane kalacak ise ayrı olarak eğitilir.\n",
    "\n",
    "**NUM_CLASSES:** 10 tane sınıfımız var.digits(0-1-2-3-4-5-6-7-8-9)\n",
    "\n",
    "**EPOCHS:** Tüm veri setini 12 kere yineliyoruz.\n",
    "(One epoch is too big to feed to the computer at once. So, we divide it in several smaller batches. We use more than one epoch because passing the entire dataset through a neural network is not enough and we need to pass the full dataset multiple times to the same neural network.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüntü boyutları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datayı alırken test ve train olarak ayırıp bünyemize katıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kullanılan Backend e göre değişiklik yapıyoruz.\n",
    "Yani data formatı konrol ediyoruz.\n",
    "\n",
    "     keras.backend.image_data_format()  \n",
    "     #ile bakabiliriz\n",
    "\n",
    "Görüntü verilerini üç boyulu bir şekilde temsil etmenin iki yolu vardır, channels_first ve channels_last :\n",
    "\n",
    "**Channels Last:** Image data is represented in a three-dimensional array where the last channel represents the color channels, \n",
    "\n",
    "*e.g. [rows][cols][channels].*\n",
    "\n",
    "**Channels First:** Image data is represented in a three-dimensional array where the first channel represents the color channels, \n",
    "\n",
    "*e.g. [channels][rows][cols].*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sınıf vektörleri ikili-binary- formuna dönüştürülüyor.\n",
    "\n",
    "(Convert Class Vector to Binary Class Matrices)\n",
    "\n",
    "to_categorical():one-hot-encoding uygulanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hazırlayacağımız model Keras'ın Sequeltial modeli. Sıralı katmanlardan oluşan bir model. Yeni bir sequential(ardışık) model objesi yaratalım,ismi de model olsun. Katmanları eklemeye başlayalım. Bunun için add() fonksiyonunu kullanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3x3 boyutunda 32 adet filtreden oluşan ReLu aktivasyonlu CONV katmanı\n",
    "eklenmesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3x3 boyutunda 64 adet filtreden oluşan ReLu aktivasyonlu CONV katmanı\n",
    "eklenmesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c02820583c63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2x2 boyutlu çerçeveden oluşan MAXPOOL katmanı eklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her seferinde nöronların %25 i atılsın.\n",
    "\n",
    "Weightlerin %25ini düşüren bir Droput katmanı ekliyoruz. Droput katmanı,Neural Networklerde overfiring i engellemek için icat edilmiş bir yöntemdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tam bağlantılı(fully connected)katmanına geçiş olacağı için düzleştirme yapılıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 nörondan oluşan ReLu aktivasyonlu FC katmanı ekleniyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her seferinde yarısını atalım nöronların"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çıkış katmanına sınıf sayısı kadar (10) Softmax aktivasyonlu nöron ekleyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adadelta optimizasyon yöntemi ve cross entropy yitim (loss) fonksiyonunun kullanımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test işlemi ve sonuçların ekrana yansıtılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Test loss: 0.02935905354363167\n",
    "    Test accuracy: 0.9908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her defasında modeli eğitmek zorunda kalmamak için eğitilmiş modelin kaydedilmesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnistCNN.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu kısımda eğitim doğruluğu ve validation accuracy eğrileri grafkte gösterilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "model = load_model('mnistCNN.h5')\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.3, callbacks=my_callbacks)\n",
    "\n",
    "epoch_list = list(range(1, len(hist.history['acc']) + 1))\n",
    "plt.plot(epoch_list, hist.history['acc'], epoch_list, hist.history['val_acc'])\n",
    "plt.legend((\"Training Accuracy\", \"Validation Accuracy\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODELİMİZİ OPENCV İLE ÖRNEKLERDE DENEME**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimizi tekrar eğitip zaman kaybetmemek için eğitilmiş modeli load_model() metodu ile yüklüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('mnistCNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers(y_pred):\n",
    "    for number, per in enumerate(y_pred[0]):\n",
    "        if per != 0:\n",
    "            final_number = str(int(number))\n",
    "            per = round((per * 100), 2)\n",
    "            return final_number, per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample'ımızı yüklüyoruz ve bazı morfolojik işlemlere tabi tutuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"MNISTsamples.png\")\n",
    "\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "img_gau = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "ret, thresh = cv2.threshold(img_gau, 80, 255, cv2.THRESH_BINARY_INV)\n",
    "#cv2.imshow(\"Frame thersh\",thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Görüntülerin erozyonu ve genişlemesi**(Erosion and Dilation of images)\n",
    "\n",
    "Erosion:Ön plan nesnesinin sınırlarını aşındırır. Bir görüntünün özelliklerini azaltmak için kullanılır.\n",
    "\n",
    "*Basics of Erosion:*\n",
    "1. Erodes away the boundaries of foreground object\n",
    "2. Used to diminish the features of an image.\n",
    "\n",
    "*Working of erosion:*\n",
    "\n",
    "1. A kernel(a matrix of odd size(3,5,7) is convolved with the image.\n",
    "2. A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "3. Thus all the pixels near boundary will be discarded depending upon the size of kernel.\n",
    "4. So the thickness or size of the foreground object decreases or simply white region decreases in the image.\n",
    "\n",
    " *Küçük beyaz gürültüleri gidermek için kullanışlıdır.\n",
    " \n",
    " *İki bağlı nesneyi ayırmak için kullanılır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilation:Nesne alanını arttırır.\n",
    "Özellikleri vurgulamak için kullanılır.\n",
    "\n",
    "*Basics of dilation:*\n",
    "1. Increases the object area\n",
    "2. Used to accentuate features\n",
    "\n",
    "*Working of dilation:*\n",
    "1. A kernel(a matrix of odd size(3,5,7) is convolved with the image\n",
    "2. A pixel element in the original image is ‘1’ if atleast one pixel under the kernel is ‘1’.\n",
    "3. It increases the white region in the image or size of foreground object increases\n",
    "\n",
    " *Gürültünün giderilmesi durumunda erozyonu dilation izler.Çünkü erozyon beyaz gürültüleri engellerken aynı zamanda nesnemizi daraltır. Bu yüzden onu genişletmeliyiz. Gürültü kaybolduğundan geri gelmeyecektir ancak nesnemizin alanı artacak bu sayede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "#cv2.imshow(\"Frame dilation\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(dilation, 50, 250)\n",
    "#cv2.imshow(\"Frame edged\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('capture.jpg',img)\n",
    "capture_img = cv2.imread('capture.jpg')\n",
    "\n",
    "img2 = capture_img.copy()\n",
    "img_gray = cv2.cvtColor(capture_img, cv2.COLOR_RGB2GRAY)\n",
    "img_gau = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "ret, thresh = cv2.threshold(img_gau, 80, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(thresh, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(dilation, 50, 250)\n",
    "\n",
    "contours, hierachy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_str = ''\n",
    "per = ''\n",
    "\n",
    "num_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sayıyı tespit halinde etrafına dikdörtgen çizmemizi sağlar ve sol üst köşesine tahmimi rakamı yazar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(contours) > 0:\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 2500:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img2, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
    "\n",
    "            new_img = thresh[y:y + h, x:x + w]\n",
    "            new_img2 = cv2.resize(new_img, (28, 28))\n",
    "            im2arr = np.array(new_img2)\n",
    "            im2arr = im2arr.reshape(1, 28, 28, 1)\n",
    "            y_pred = model.predict(im2arr)\n",
    "\n",
    "            num, per = get_numbers(y_pred)\n",
    "            num_list.append(str(int(num)))\n",
    "            num_str = '[' + str(str(int(num))) + ']'\n",
    "            cv2.putText(img2, num_str, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "str1 burada tahmin edilen sayılar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = ' '.join(num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahmini sayıları frame in sol üstüne yazdıran kısım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (str1 != ''):\n",
    "    y_p = str('Predicted Value is ' + str(str1))\n",
    "    print(y_p)\n",
    "    cv2.putText(img2, y_p, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Capture Frame\", img2)\n",
    "#cv2.imshow(\"Contours Frame\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1():\n",
    "    n = 1000000\n",
    "    if n != 0:\n",
    "        n -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 ns ± 38.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
